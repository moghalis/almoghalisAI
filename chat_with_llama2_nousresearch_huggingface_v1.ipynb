{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#üìöüìå Introduction: Chatting with LLaMA 2 using Hugging Face ü§óü¶ô\n",
        "In this notebook, you'll learn how to build a chat interface with the LLaMA 2 (7B) model, specifically the NousResearch/Llama-2-7b-chat-hf variant and the original meta-llama/Llama-2-7b-chat both hosted on Hugging Face. This model is a fine-tuned version of Meta's LLaMA 2 architecture, optimized for engaging, instruction-following conversations ‚Äî similar to ChatGPT.\n",
        "\n",
        "üöÄ Objectives:\n",
        "\n",
        "- Comparing Meta's LLaMA 2 and NousResearch's Fine-Tuned Variant\n",
        "\n",
        "- Load and use a conversational LLM from Hugging Face\n",
        "\n",
        "- Structure chat history for multi-turn dialogue\n",
        "\n",
        "- Generate coherent and context-aware responses using transformers and pipeline\n",
        "\n",
        "- Explore the power of open-source LLMs without running them locally\n",
        "\n",
        "üë®‚Äçüíª Whether you're a developer, data scientist, or AI enthusiast, this notebook helps you quickly start chatting with one of the most capable open-access LLMs available. üß†üí¨\n",
        "\n",
        "üìπ This video tutorial on my YouTube channel walks you through each step of the process ‚Äî with explanations, code execution, and real-time results. üîçüí° Make sure to follow along, try it out, and see how easy it is to chat with LLaMA 2 using Hugging Face! ü§ñ‚ú®\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8wYWEQWZ9E2L"
      },
      "id": "8wYWEQWZ9E2L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üîç Comparing Meta's LLaMA 2 and NousResearch's Fine-Tuned Variant üß†üí¨\n",
        "\n",
        "When working with open LLMs on Hugging Face, it's important to understand the difference between the **base models** and their **fine-tuned chat-ready variants**. In this notebook, we use the `NousResearch/Llama-2-7b-chat-hf` model ‚Äî a fine-tuned version of Meta's foundational LLaMA 2.\n",
        "\n",
        "Here's a breakdown of the differences between the two:\n",
        "\n",
        "| Feature | üß™ [Meta's LLaMA 2](https://huggingface.co/meta-llama/Llama-2-7b-chat) (`meta-llama/Llama-2-7b-chat-hf`) | üõ†Ô∏è [NousResearch](https://huggingface.co/NousResearch/Llama-2-7b-chat-hf) (`NousResearch/Llama-2-7b-chat-hf`) |\n",
        "|--------|------------------------------------------------------|-----------------------------------------------------|\n",
        "| **Source** | Meta AI | Fine-tuned by NousResearch |\n",
        "| **Type** | Pretrained, base LLM | Fine-tuned for chat/instruction |\n",
        "| **Use Case** | General-purpose language tasks | Conversational AI, instruction following |\n",
        "| **Access** | Requires access token + approval üîê | Publicly available on Hugging Face üÜì |\n",
        "| **Optimized for Chat?** | ‚ùå Not directly | ‚úÖ Yes |\n",
        "| **Best for** | Researchers and developers seeking raw LLaMA 2 | Anyone building chatbots or dialogue systems |\n",
        "\n",
        "### ‚úÖ Summary:\n",
        "The `NousResearch` version is essentially **Meta‚Äôs LLaMA 2 (7B)** ‚Äî but **fine-tuned**, **more accessible**, and **optimized** for **real-world chat experiences**. If you're building chat applications or testing dialogue systems, it's the faster and friendlier starting point! üöÄ"
      ],
      "metadata": {
        "id": "NcxO2Cdm97-b"
      },
      "id": "NcxO2Cdm97-b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß∞ Install Required Libraries\n"
      ],
      "metadata": {
        "id": "CWRaEKc2_xwx"
      },
      "id": "CWRaEKc2_xwx"
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install -U torch==2.0.1 \\\n",
        "#  transformers==4.33.0 \\\n",
        "#  sentencepiece==0.1.99 \\\n",
        "#  accelerate==0.22.0 # needed for low_cpu_mem_usage parameter"
      ],
      "metadata": {
        "id": "4PHsB_3a6Cxf"
      },
      "id": "4PHsB_3a6Cxf",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîß Load the Chat Model and Tokenizer for `NousResearch/Llama-2-7b-chat-hf` model and tokenizer from Hugging Face"
      ],
      "metadata": {
        "id": "KCo0ALVdATa4"
      },
      "id": "KCo0ALVdATa4"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b48c0687-ade4-4e7e-812a-99f0cfeca9c4",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "563da4af7d32496e9c809c4bc7f134d8",
            "44355499a5b1473597f85b219aa928c5",
            "d27099d570224cf1b17a94cfbf7ba2a2",
            "9f2e7e1f5e1742d5b980041959bf26fe",
            "a47bbc27b67f474c8e854fefa64e22c9",
            "ceba826ccd3e466cb2bf6367c66abf78",
            "e1c3f2427144449faeec6b63ec2e0941",
            "869934b13e0d4f6da20f0fd0f92d41b9",
            "0c133850179041368ec49cd0b898f723",
            "d2b5fb9c0a2e4d0486c388983590e42a",
            "261b71b131774dc58bcd1a2755251d75"
          ]
        },
        "id": "b48c0687-ade4-4e7e-812a-99f0cfeca9c4",
        "outputId": "d29c8f27-a009-4149-cbd1-0f3983090471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "563da4af7d32496e9c809c4bc7f134d8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import LlamaTokenizer,LlamaForCausalLM\n",
        "\n",
        "model_checkpoint = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "\n",
        "tokenizer = LlamaTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    low_cpu_mem_usage=True,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üß© Preparing Messages for LLaMA Chat Format\n",
        "\n",
        "This utility function transforms a list of message histories into properly formatted input prompts for LLaMA-style chat models, following the instruction formatting used in many fine-tuned Hugging Face models.\n",
        "\n",
        "### üîç What the Code Does:\n",
        "- Defines a `Message` structure with roles (`system`, `user`, `assistant`) and content.\n",
        "- Prepares messages with system instructions using special tokens like `<<SYS>>` and `[INST]...[/INST]`.\n",
        "- Verifies correct message ordering:\n",
        "  - A `system` message (optional, must be first)\n",
        "  - Followed by alternating `user` and `assistant` messages\n",
        "  - Ending with a `user` message\n",
        "- Builds input strings by interleaving user and assistant turns, wrapped in `[INST]` tags, and adds `bos_token` and `eos_token` as required by the tokenizer.\n",
        "- Ensures the format is compatible with models expecting instruction-style inputs (like LLaMA-2 chat variants).\n",
        "\n",
        "üõ†Ô∏è This function is adapted from [llama-cpp-chat-completion-wrapper](https://github.com/viniciusarruda/llama-cpp-chat-completion-wrapper/blob/1c9e29b70b1aaa7133d3c7d7b59a92d840e92e6d/llama_cpp_chat_completion_wrapper.py)\n",
        "\n"
      ],
      "metadata": {
        "id": "w7CI81KDAt6i"
      },
      "id": "w7CI81KDAt6i"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4eeaafdb-8482-4491-bba2-5b3b389813c3",
      "metadata": {
        "tags": [],
        "id": "4eeaafdb-8482-4491-bba2-5b3b389813c3"
      },
      "outputs": [],
      "source": [
        "# based on https://github.com/viniciusarruda/llama-cpp-chat-completion-wrapper/blob/1c9e29b70b1aaa7133d3c7d7b59a92d840e92e6d/llama_cpp_chat_completion_wrapper.py\n",
        "\n",
        "from typing import List\n",
        "from typing import Literal\n",
        "from typing import TypedDict\n",
        "\n",
        "from transformers import PreTrainedTokenizer\n",
        "\n",
        "Role = Literal[\"system\", \"user\", \"assistant\"]\n",
        "\n",
        "class Message(TypedDict):\n",
        "    role: Role\n",
        "    content: str\n",
        "\n",
        "MessageList = List[Message]\n",
        "\n",
        "BEGIN_INST, END_INST = \"[INST] \", \" [/INST] \"\n",
        "BEGIN_SYS, END_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
        "\n",
        "def convert_list_of_message_lists_to_input_prompt(list_of_message_lists: List[MessageList], tokenizer: PreTrainedTokenizer) -> List[str]:\n",
        "    input_prompts: List[str] = []\n",
        "    print(type(list_of_message_lists))\n",
        "    print(type(list_of_message_lists[0]))\n",
        "    for message_list in list_of_message_lists:\n",
        "        if message_list[0][\"role\"] == \"system\":\n",
        "            content = \"\".join([BEGIN_SYS, message_list[0][\"content\"], END_SYS, message_list[1][\"content\"]])\n",
        "            message_list = [{\"role\": message_list[1][\"role\"], \"content\": content}] + message_list[2:]\n",
        "\n",
        "        if not (\n",
        "            all([msg[\"role\"] == \"user\" for msg in message_list[::2]])\n",
        "            and all([msg[\"role\"] == \"assistant\" for msg in message_list[1::2]])\n",
        "        ):\n",
        "            raise ValueError(\n",
        "                \"Format must be in this order: 'system', 'user', 'assistant' roles.\\nAfter that, you can alternate between user and assistant multiple times\"\n",
        "            )\n",
        "\n",
        "        eos = tokenizer.eos_token\n",
        "        bos = tokenizer.bos_token\n",
        "        input_prompt = \"\".join(\n",
        "            [\n",
        "                \"\".join([bos, BEGIN_INST, (prompt[\"content\"]).strip(), END_INST, (answer[\"content\"]).strip(), eos])\n",
        "                for prompt, answer in zip(message_list[::2], message_list[1::2])\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        if message_list[-1][\"role\"] != \"user\":\n",
        "            raise ValueError(f\"Last message must be from user role. Instead, you sent from {message_list[-1]['role']} role\")\n",
        "\n",
        "        input_prompt += \"\".join([bos, BEGIN_INST, (message_list[-1][\"content\"]).strip(), END_INST])\n",
        "\n",
        "        input_prompts.append(input_prompt)\n",
        "\n",
        "    return input_prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " üß™ Creating and Formatting a Simple Chat Prompt\n",
        "\n",
        "Here we construct a basic chat scenario using the `Message` format defined earlier. Note that:\n",
        "\n",
        "- üõ† A **system message** instructing the assistant to respond only with emojis\n",
        "- üë§ A **user message** asking a questionon behalf of user\n",
        "- üß± These messages are added to a list and passed into our `convert_list_of_message_lists_to_input_prompt()` function to generate a LLaMA-compatible chat prompt\n",
        "\n",
        "This shows how to structure a minimal, valid input for models expecting `[INST]`-formatted chat inputs.\n",
        "\n",
        "üßµ The resulting `prompt` can then be passed into the model for response generation."
      ],
      "metadata": {
        "id": "atOB045ABuUS"
      },
      "id": "atOB045ABuUS"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1cf0ab54-bbad-42b9-a2ba-17cf4e28fbee",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cf0ab54-bbad-42b9-a2ba-17cf4e28fbee",
        "outputId": "5bf82af1-7843-4ce7-9a94-0bdb841252fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'role': 'system', 'content': 'Answer only with emojis'}\n",
            "{'role': 'user', 'content': 'Who won the 2019 Stanley Hockey Cup?'}\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "['<s>[INST] <<SYS>>\\nAnswer only with emojis\\n<</SYS>>\\n\\nWho won the 2019 Stanley Hockey Cup? [/INST] ']\n"
          ]
        }
      ],
      "source": [
        "system_message = Message()\n",
        "system_message[\"role\"] = \"system\"\n",
        "system_message[\"content\"] = \"Answer only with emojis\"\n",
        "print(system_message)\n",
        "\n",
        "user_message = Message()\n",
        "user_message[\"role\"] = \"user\"\n",
        "user_message[\"content\"] = \"Who won the 2019 Stanley Hockey Cup?\"\n",
        "print(user_message)\n",
        "\n",
        "# assistant_message = Message()\n",
        "# assistant_message.role = \"assistant\"\n",
        "# assistant_message.content = \"\"\n",
        "\n",
        "list_of_messages = list()\n",
        "list_of_messages.append(system_message)\n",
        "list_of_messages.append(user_message)\n",
        "\n",
        "list_of_message_lists = list()\n",
        "list_of_message_lists.append(list_of_messages)\n",
        "\n",
        "prompt = convert_list_of_message_lists_to_input_prompt(list_of_message_lists, tokenizer)\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Generate Text from a prompt using pipeline API\n",
        "\n",
        "- Tokenize the input prompt.\n",
        "\n",
        "- Configure the length of the prompt in tokens is printed for reference.\n",
        "\n",
        "- User `GenerationConfig` object is used to control generation parameters, such as the max_new_tokens.\n",
        "\n",
        "- Finally, use `pipeline` API is called to generate text based on the model and tokenizer provided."
      ],
      "metadata": {
        "id": "oYuT4mmNCfPH"
      },
      "id": "oYuT4mmNCfPH"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "703f96ed-08a1-466f-8b67-919ac7e1e1a3",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "703f96ed-08a1-466f-8b67-919ac7e1e1a3",
        "outputId": "68721956-3912-4e3d-f7df-c01a6a1335bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt is 41 tokens\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "tokenized_prompt = tokenizer(prompt)\n",
        "\n",
        "print(f'prompt is {len(tokenized_prompt[\"input_ids\"][0])} tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "80143960-fc13-47ca-a1a1-4a22446eaebf",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80143960-fc13-47ca-a1a1-4a22446eaebf",
        "outputId": "4f5ea5d7-8da5-418f-ce6b-eb1c6581c183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "from transformers import GenerationConfig\n",
        "\n",
        "generation_config = GenerationConfig(max_new_tokens=2000)\n",
        "\n",
        "pipeline = pipeline(\"text-generation\",\n",
        "                    model=model,\n",
        "                    tokenizer=tokenizer,\n",
        "                    generation_config=generation_config, return_full_text=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "702a3695-8c9a-4978-8b90-5b39ab22cf8f",
      "metadata": {
        "tags": [],
        "id": "702a3695-8c9a-4978-8b90-5b39ab22cf8f"
      },
      "outputs": [],
      "source": [
        "response = pipeline(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo9vY0YEnG6Z",
        "outputId": "11a88c9a-67e2-4665-9fc6-409f60d738fe"
      },
      "id": "Vo9vY0YEnG6Z",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': ' Here is my answer:\\n\\nüèíüèàüèÜ'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " üß™ Let's try a simpler prompt way to simlplify what happens inside `pipeline` API\n"
      ],
      "metadata": {
        "id": "_O-tkvXQFjJu"
      },
      "id": "_O-tkvXQFjJu"
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"<<SYS>>\\nYou are a helpful assistant that provides concise and informative answers.\\n<<SYS>>\"\n",
        "\n",
        "user_prompt = \"What is the capital of Canada?\"\n",
        "\n",
        "# Prompt format\n",
        "prompt = system_prompt + \"\\n\" + user_prompt\n",
        "\n",
        "print(prompt)\n",
        "\n",
        "# 1. tokenize the prompt into tokens\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# 2. Pass the tokens to the model to generate a response in tokens\n",
        "output = model.generate(input_ids, max_length=50)\n",
        "\n",
        "# 3. Decode the response back\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the response\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "yiHqwE0PncTX",
        "outputId": "b1e6bdaf-dc51-4898-9560-582e7fff3695"
      },
      "id": "yiHqwE0PncTX",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<SYS>>\n",
            "You are a helpful assistant that provides concise and informative answers.\n",
            "<<SYS>>\n",
            "What is the capital of Canada?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<<SYS>>\\nYou are a helpful assistant that provides concise and informative answers.\\n<<SYS>>\\nWhat is the capital of Canada?\\n<</PAGE>>\\nThe capital of Canada is Ottawa.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nq5iM4wMp8Xl",
        "outputId": "3609e4a1-2a52-44f2-e086-fb347573b639"
      },
      "id": "nq5iM4wMp8Xl",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<<SYS>>\\nYou are a helpful assistant that provides concise and informative answers.\\n<<SYS>>\\nWhat is the capital of Canada?\\n<</PAGE>>\\nThe capital of Canada is Ottawa.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " üß™ Calling `pipeline` while passing the prompt to generate a response in a single line...\n"
      ],
      "metadata": {
        "id": "aTLHn1reGT8h"
      },
      "id": "aTLHn1reGT8h"
    },
    {
      "cell_type": "code",
      "source": [
        "response = pipeline(prompt)"
      ],
      "metadata": {
        "id": "2cJx6N5_pzlc"
      },
      "id": "2cJx6N5_pzlc",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAvSGgjop0nk",
        "outputId": "e5ef82a5-4270-452a-e07a-ae9c6466df09"
      },
      "id": "rAvSGgjop0nk",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'generated_text': '\\n<</PAGE>>\\nThe capital of Canada is Ottawa.'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîÅ Repeating the Code with `meta-llama/Llama-2-7b-chat-hf`\n",
        "\n",
        "In this section, we're reusing the earlier code, but this time loading the **LLaMA 2 model** from **Meta AI** instead of a community model like the one from `NousResearch`.\n",
        "\n",
        "‚ö†Ô∏è **Note**: Access to Meta's LLaMA models requires logging into the Hugging Face Hub and requesting access to the model page.\n",
        "\n",
        "Make sure you have:\n",
        "- üîê Logged into Hugging Face using `notebook_login()`\n",
        "- ‚úÖ Been granted access to `meta-llama/Llama-2-7b-chat-hf`\n",
        "\n",
        "This version loads the model and tokenizer from Meta, formats a prompt using a system message and user question, tokenizes it, and generates a concise response using the LLaMA 2 model.\n",
        "\n",
        "üìå The setup uses `torch.float16` for efficient inference and `device_map=\"auto\"` to automatically assign model parts to available devices."
      ],
      "metadata": {
        "id": "WcJoZQBjGvLX"
      },
      "id": "WcJoZQBjGvLX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.üê±‚Äçüíª Hugging Face Hub Login\n",
        "\n",
        "The notebook_login() function will prompt for your credentials üîë, giving you access to the Hub's resources.\n",
        "#### How to Generate Tokens from Your Hugging Face Account\n",
        "\n",
        "1. üñ•Ô∏è **Go to Hugging Face Website**\n",
        "   - Visit [Hugging Face](https://huggingface.co/).\n",
        "\n",
        "2. üîë **Log In to Your Account**\n",
        "\n",
        "3. üë§ **Navigate to Your Settings by Clicking on your profile icon and select Settings**\n",
        "\n",
        "4. üîê **Generate a New Token** (Access Token)\n",
        "   - In the **Access Tokens** section on the left side of the settings page, click on **New Token**.\n",
        "   - Give your token a name (e.g., \"Jupyter Notebook\") and select the scope (permissions) for the token (e.g., **read**, **write**, or **admin**).\n",
        "   - Click **Generate**.\n",
        "\n",
        "5. üìÑ **Copy Your Token**\n",
        "\n",
        "6. üîÑ **Use the Token in Your Code**\n",
        "   - You can now use this token in your code, like in `notebook_login()` or when interacting with the Hugging Face Hub via the `transformers` library."
      ],
      "metadata": {
        "id": "K-2NUOXpGzg7"
      },
      "id": "K-2NUOXpGzg7"
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "c8cba2bb8ee4427bb5bfcba6e67722e7",
            "ae7d8907193148bcb774308f6a760b4d",
            "f889516e7114405186e5fca4da27234f",
            "abea91f233b646d992d3b6e08e683188",
            "a80030c802e94eea954cf77303970217",
            "6eacb7c5d7fc4fb5a186d5d8bb8b9fa9",
            "de590d64c92c4cf4bd6ece420eb9f700",
            "ba9f1cdabdd744a786e3342fdd3870da",
            "9e5b31c65f5a432f80a45203805ac1fd",
            "7209e961f48046dd91dcc4abb374e113",
            "be3ca9238e5d48c6a66d078c8ce824a9",
            "f930032b820140f3b80fe7ea7d242102",
            "724a32b58c52475092547864e6b8853d",
            "a9094e7ff9944719ac4dac22ebd5eb7c",
            "6c3ec437592645dcbb573be54f415847",
            "119c04a7ba914533bc9339e5bb12299f",
            "10b9f62300b348d5bec9e5b942edfc28",
            "6bd0696f696b44778948b57296a8c318",
            "f9d4570417b24c549f33664be760c4cb",
            "43efa0e71f3046a28800924f2c6e55a8"
          ]
        },
        "id": "FFjJjPD2uAMi",
        "outputId": "8f3c3e35-0fda-4af4-8b23-3f2d12f042bc"
      },
      "id": "FFjJjPD2uAMi",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8cba2bb8ee4427bb5bfcba6e67722e7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. üîÅ Using `meta-llama/Llama-2-7b-chat-hf` Instead of NousResearch\n",
        "\n",
        "We're repeating the same code, but this time using **Meta's LLaMA 2** model from Hugging Face: `meta-llama/Llama-2-7b-chat-hf`.\n",
        "\n",
        "- Loads the Meta model\n",
        "- Formats a prompt\n",
        "- Tokenizes it\n",
        "- Generates a concise response.\n",
        "\n",
        "**Note** : We use `torch.float16` for efficiency and `device_map=\"auto\"` for device placement.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cPxgSGlAILZd"
      },
      "id": "cPxgSGlAILZd"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
        "\n",
        "# 1. Load the model and tokenizer\n",
        "model_dir = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "model = LlamaForCausalLM.from_pretrained(model_dir, device_map=\"auto\", torch_dtype=torch.float16)\n",
        "tokenizer = LlamaTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "# 2. Create the system prompt\n",
        "system_prompt = \"<<SYS>>\\nYou are a helpful assistant that provides concise and informative answers.\\n<<SYS>>\"\n",
        "\n",
        "# 3. Define the user prompt\n",
        "user_prompt = \"What is the capital of Canada?\"\n",
        "\n",
        "# 4. Format the whole prompt\n",
        "prompt = system_prompt + \"\\n\" + user_prompt\n",
        "\n",
        "# 5. Tokenize the prompt\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# 6. Generate a response (Tokens)\n",
        "output = model.generate(input_ids, max_length=50)\n",
        "\n",
        "# 7. Decode the response (from generated tokens)\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# 8. Print the response\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "3b99634c745343d8990a3e1b07351d82",
            "9153fe496c4045e38ccf0d2fc6baa1d2",
            "95736eb0dd16443190cb4ebf87c7bded",
            "da1cd37e34fd45c0b8a446571935803f",
            "9526a295b03d4260878fb8d0d0b42060",
            "b2234741e5464f519dbbc30c169bcef8",
            "291f1e17fcd54c68b2a2c151d7dbf761",
            "f7130584b043449ea9d2b6b08ae285d5",
            "ab5b055574de413c96d37c9b72054380",
            "95ea20af86744abeae9cf1b20191878e",
            "fff89be7213a441bab0ff1f702bb28d8"
          ]
        },
        "id": "tIxK99ezaED2",
        "outputId": "8b4f6413-8187-49da-e5f4-6c40094516db"
      },
      "id": "tIxK99ezaED2",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b99634c745343d8990a3e1b07351d82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<SYS>>\n",
            "You are a helpful assistant that provides concise and informative answers.\n",
            "<<SYS>>\n",
            "What is the capital of Canada?\n",
            "<</PAGE>>\n",
            "The capital of Canada is Ottawa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_TVges7ncFGY"
      },
      "id": "_TVges7ncFGY",
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      }
    ],
    "instance_type": "ml.g5.4xlarge",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "563da4af7d32496e9c809c4bc7f134d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44355499a5b1473597f85b219aa928c5",
              "IPY_MODEL_d27099d570224cf1b17a94cfbf7ba2a2",
              "IPY_MODEL_9f2e7e1f5e1742d5b980041959bf26fe"
            ],
            "layout": "IPY_MODEL_a47bbc27b67f474c8e854fefa64e22c9"
          }
        },
        "44355499a5b1473597f85b219aa928c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceba826ccd3e466cb2bf6367c66abf78",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e1c3f2427144449faeec6b63ec2e0941",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "d27099d570224cf1b17a94cfbf7ba2a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869934b13e0d4f6da20f0fd0f92d41b9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c133850179041368ec49cd0b898f723",
            "value": 2
          }
        },
        "9f2e7e1f5e1742d5b980041959bf26fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2b5fb9c0a2e4d0486c388983590e42a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_261b71b131774dc58bcd1a2755251d75",
            "value": "‚Äá2/2‚Äá[00:05&lt;00:00,‚Äá‚Äá2.55s/it]"
          }
        },
        "a47bbc27b67f474c8e854fefa64e22c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceba826ccd3e466cb2bf6367c66abf78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c3f2427144449faeec6b63ec2e0941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "869934b13e0d4f6da20f0fd0f92d41b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c133850179041368ec49cd0b898f723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2b5fb9c0a2e4d0486c388983590e42a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "261b71b131774dc58bcd1a2755251d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8cba2bb8ee4427bb5bfcba6e67722e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_de590d64c92c4cf4bd6ece420eb9f700"
          }
        },
        "ae7d8907193148bcb774308f6a760b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba9f1cdabdd744a786e3342fdd3870da",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9e5b31c65f5a432f80a45203805ac1fd",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "f889516e7114405186e5fca4da27234f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7209e961f48046dd91dcc4abb374e113",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_be3ca9238e5d48c6a66d078c8ce824a9",
            "value": ""
          }
        },
        "abea91f233b646d992d3b6e08e683188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_f930032b820140f3b80fe7ea7d242102",
            "style": "IPY_MODEL_724a32b58c52475092547864e6b8853d",
            "value": true
          }
        },
        "a80030c802e94eea954cf77303970217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a9094e7ff9944719ac4dac22ebd5eb7c",
            "style": "IPY_MODEL_6c3ec437592645dcbb573be54f415847",
            "tooltip": ""
          }
        },
        "6eacb7c5d7fc4fb5a186d5d8bb8b9fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_119c04a7ba914533bc9339e5bb12299f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_10b9f62300b348d5bec9e5b942edfc28",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "de590d64c92c4cf4bd6ece420eb9f700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "ba9f1cdabdd744a786e3342fdd3870da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e5b31c65f5a432f80a45203805ac1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7209e961f48046dd91dcc4abb374e113": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be3ca9238e5d48c6a66d078c8ce824a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f930032b820140f3b80fe7ea7d242102": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "724a32b58c52475092547864e6b8853d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9094e7ff9944719ac4dac22ebd5eb7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c3ec437592645dcbb573be54f415847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "119c04a7ba914533bc9339e5bb12299f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10b9f62300b348d5bec9e5b942edfc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bd0696f696b44778948b57296a8c318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9d4570417b24c549f33664be760c4cb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_43efa0e71f3046a28800924f2c6e55a8",
            "value": "Connecting..."
          }
        },
        "f9d4570417b24c549f33664be760c4cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43efa0e71f3046a28800924f2c6e55a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b99634c745343d8990a3e1b07351d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9153fe496c4045e38ccf0d2fc6baa1d2",
              "IPY_MODEL_95736eb0dd16443190cb4ebf87c7bded",
              "IPY_MODEL_da1cd37e34fd45c0b8a446571935803f"
            ],
            "layout": "IPY_MODEL_9526a295b03d4260878fb8d0d0b42060"
          }
        },
        "9153fe496c4045e38ccf0d2fc6baa1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2234741e5464f519dbbc30c169bcef8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_291f1e17fcd54c68b2a2c151d7dbf761",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "95736eb0dd16443190cb4ebf87c7bded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7130584b043449ea9d2b6b08ae285d5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab5b055574de413c96d37c9b72054380",
            "value": 2
          }
        },
        "da1cd37e34fd45c0b8a446571935803f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95ea20af86744abeae9cf1b20191878e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fff89be7213a441bab0ff1f702bb28d8",
            "value": "‚Äá2/2‚Äá[00:04&lt;00:00,‚Äá‚Äá1.97s/it]"
          }
        },
        "9526a295b03d4260878fb8d0d0b42060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2234741e5464f519dbbc30c169bcef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "291f1e17fcd54c68b2a2c151d7dbf761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7130584b043449ea9d2b6b08ae285d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab5b055574de413c96d37c9b72054380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95ea20af86744abeae9cf1b20191878e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff89be7213a441bab0ff1f702bb28d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}