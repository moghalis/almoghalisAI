{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK87_2B054pq"
      },
      "source": [
        "# üß† Exploring Amazon Rekognition for Face, Celebrity, Content & Text Detection\n",
        "##  Amazon Rekognition Tutorial: Image & Video Intelligence with **No ML Required!** üé•üì∏\n",
        "# ü§ñ Amazon Rekognition Deep Dive with Python üß†\n",
        "\n",
        "Welcome to this hands-on tutorial where we explore the powerful capabilities of **Amazon Rekognition**, AWS's cloud-based computer vision service!üöÄüñºÔ∏èüé•\n",
        "\n",
        "In this notebook, you'll learn how to:\n",
        "üîç Detect **faces** and analyze facial attributes\n",
        "üåü Recognize **celebrities** in images and videos\n",
        "üö´ **Content Moderation** ‚Äì Flag unsafe, explicit, or violent content  \n",
        "üìù **Text Detection** ‚Äì Extract text from images and video frames  \n",
        "üéØ **Object & Scene Detection** ‚Äì Identify items and scenes in media  \n",
        "üé≠ **Emotion & Attribute Analysis** ‚Äì Understand facial expressions and characteristics  \n",
        "\n",
        "All examples use the official **Boto3 AWS SDK** and real use-case scenarios to help you build intelligent applications. This tutorial is perfect for developers, ML engineers, and data scientists who want to integrate cloud-based vision AI into their pipelines without training models from scratch. üôå\n",
        "\n",
        "## üõ†Ô∏è Technologies Used:\n",
        "- Amazon Rekognition\n",
        "- Boto3 (AWS SDK for Python)\n",
        "- Jupyter Notebooks\n",
        "- AWS S3 (for image/video storage)\n",
        "\n",
        "‚úÖ **What You‚Äôll Practice**:\n",
        "- Uploading and analyzing images/videos from S3\n",
        "- Using Python SDK (`boto3`) to call Rekognition APIs\n",
        "- Real use cases for public safety, content moderation, identity verification, and media indexing\n",
        "\n",
        "üëâ Ideal for developers, researchers, or businesses exploring scalable image/video analytics.\n",
        "\n",
        "Let‚Äôs turn your data into vision! üëÅÔ∏èüíª‚ú®\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMy98c5Q-3Xw"
      },
      "source": [
        "## üöÄ Environment Setup & Initialization\n",
        "\n",
        "In this section, we import necessary libraries, prepare directories, and set up sessions with Amazon services. This includes preparing SageMaker and making sure local storage is ready for temporary media processing.\n",
        "\n",
        "####  Importing Required Libraries\n",
        "We start by importing essential Python libraries üì¶ such as `boto3` for accessing AWS services and interaction, SageMaker SDK, image display utilities, `PIL` for image processing, `matplotlib` for visualization, and `os` for file path operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RTWX99_31uT"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import sagemaker\n",
        "from IPython.display import HTML, display, Image as IImage\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGZA_dWwBmoI"
      },
      "source": [
        "#### ü§ñ Initializing Rekognition Client\n",
        "\n",
        "Here we create a `boto3` client for Amazon Rekognition. This allows us to interact with Rekognition APIs to analyze images and videos stored in S3 or local files.\n",
        "Set up SageMaker session, get default role, bucket, and region. Create Rekognition and S3 clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A9fiA7Q31uV"
      },
      "outputs": [],
      "source": [
        "sagemaker_session = sagemaker.Session()\n",
        "role = sagemaker.get_execution_role()\n",
        "bucket = sagemaker_session.default_bucket()\n",
        "region = boto3.Session().region_name\n",
        "\n",
        "#Define client for Amazon Rekognition and S3\n",
        "rekognition = boto3.client(\"rekognition\")\n",
        "s3 = boto3.client(\"s3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-og6w0TFB3tm"
      },
      "source": [
        "#### üóÇÔ∏è Creating Temporary Directory\n",
        "\n",
        "This command creates a local `./temp` folder where images and videos will be stored temporarily for processing with Amazon Rekognition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmCsIxYr31uX"
      },
      "outputs": [],
      "source": [
        "#!mkdir -p ./temp\n",
        "temp_folder = \"temp/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZPMSHDE31ua"
      },
      "source": [
        "## üñºÔ∏è Image Display Utilities\n",
        "\n",
        "Here we define helper function `drwBoundingBoxes` to display images and overlay bounding boxes. This function will be used to visualize detected faces, labels, and moderation outcomes returned by Rekognition. It draws bounding boxes around detected entities like faces or text using their coordinates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy4OnDqS31ua"
      },
      "outputs": [],
      "source": [
        "def drwBoundingBoxes(imageFrame, boxes):\n",
        "    colorsTuples = ((255, 0, 0), (0, 255, 0), (0, 0, 255), (50, 190, 120))\n",
        "\n",
        "    # Let's store the image in the temporary local folder we created\n",
        "    imageDir = temp_folder + os.path.basename(imageFrame)\n",
        "    #doanload the image frame from S3\n",
        "    s3.download_file(bucket, imageFrame, imageDir)\n",
        "\n",
        "    # Draws Bounding Box on Image\n",
        "    boundedImage = Image.open(imageDir)\n",
        "    drw = ImageDraw.Draw(boundedImage)\n",
        "    w, h = boundedImage.size #get image width, height\n",
        "    color = 0\n",
        "    maxColor = len(colorsTuples)\n",
        "    boxLines = 3 # 4 lines: 0-3\n",
        "    #box coordinates (x1, y1) and (x2, y2)\n",
        "    for b in boxes:\n",
        "        x1 = int(b[1][\"Left\"] * w)\n",
        "        y1 = int(b[1][\"Top\"] * h)\n",
        "        x2 = int(b[1][\"Left\"] * w + b[1][\"Width\"] * w)\n",
        "        y2 = int(b[1][\"Top\"] * h + b[1][\"Height\"] * h)\n",
        "\n",
        "        drw.text((x1, y1), b[0], colorsTuples[color])\n",
        "        for line in range(boxLines):\n",
        "            drw.rectangle((x1 - line, y1 - line, x2 + line, y2 + line), outline=colorsTuples[color])\n",
        "        color = (color + 1) % maxColor\n",
        "\n",
        "    imgFormat = \"PNG\"\n",
        "    extension = imgFormat.lower()\n",
        "    if extension.endswith(\"jpg\") or extension.endswith(\"jpeg\"):\n",
        "        imgFormat = \"JPEG\"\n",
        "\n",
        "    boundedImage.save(imageDir, format=imgFormat)\n",
        "\n",
        "    display(boundedImage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maWU6WuN31uN"
      },
      "source": [
        "# Part 1: üë§ Face Detection & Analysis\n",
        "\n",
        "Amazon Rekognition can detect faces in images and analyze attributes like age range, emotions, and pose. In this section, we will send an image to the Amazon Rekognition API and extracts insights for us üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XglU5_xD31uX"
      },
      "source": [
        "# Recognize Celebrities in Images\n",
        "\n",
        "#### üñºÔ∏è Loading and Displaying an Image\n",
        "\n",
        "We fetch an image stored on S3 using a presigned URL and display it to verify that it was retrieved successfully.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4wxu0SK31uY"
      },
      "outputs": [],
      "source": [
        "#import and view image from directory\n",
        "imageFileName = \"media/mi6.png\"\n",
        "display(IImage(url=s3.generate_presigned_url(\"get_object\", Params={\"Bucket\": bucket, \"Key\": imageFileName}), width=350, height=150))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpNYt8GQ31ua"
      },
      "source": [
        "#### üëÅÔ∏è Detecting Faces in an Image\n",
        "\n",
        "This cell sends the image to the Rekognition `recognize_celebrities()` API from Amazon Rekognition to identify celebritie, facial landmarks and attributes such as emotions, age range, gender, and smile. This can be useful in media, entertainment, and archival use cases.\n",
        "\n",
        "What celebrities information returned inside JSON response:\n",
        "\n",
        "- Name\n",
        "- Id\n",
        "- Urls\n",
        "- Facial attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12J0fRwS31uZ"
      },
      "outputs": [],
      "source": [
        "#\n",
        "recognizedCelebsResponse = rekognition.recognize_celebrities(\n",
        "    Image={\n",
        "        \"S3Object\": {\n",
        "            \"Bucket\": bucket, #default_bucket\n",
        "            \"Name\": imageFileName, # MI6 movie shot\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "display(recognizedCelebsResponse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbvncGWOZhzu"
      },
      "source": [
        "#### üì¶ Parse and Visualize Recognized Celebrities  \n",
        "We extract celebrity names and their bounding box coordinates from the JSON output and visualize them on the original image using the helper function `drwBoundingBoxes` to draw bounding box around each face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xvLHZeB31ub"
      },
      "outputs": [],
      "source": [
        "boundingBoxes = []\n",
        "allCelebrities = recognizedCelebsResponse[\"CelebrityFaces\"]\n",
        "for c in allCelebrities:\n",
        "    boundingBoxes.append((c[\"Name\"], c[\"Face\"][\"BoundingBox\"]))\n",
        "print(\"Number of Celebrities found: \", len(boundingBoxes))\n",
        "drwBoundingBoxes(imageFileName, boundingBoxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KAFNYV631ub"
      },
      "source": [
        "### üéûÔ∏è Display Trailer Video  \n",
        "We generate and display a pre-signed S3 URL for a video to be used in video-based celebrity recognition tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhZBLVcQ31uc"
      },
      "outputs": [],
      "source": [
        "videoFileName = \"media/mi6Trailer.mp4\" # Our MI6 trimmed trailer 33 seconds\n",
        "\n",
        "videoS3URL=s3.generate_presigned_url(\"get_object\", Params={\"Bucket\": bucket, \"Key\": videoFileName})\n",
        "videoHTML = \"<video controls='controls' width='640' height='360' name='Video' src='{0}'></video>\".format(videoS3URL)\n",
        "display(HTML(videoHTML))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph4Q_Omx31uc"
      },
      "source": [
        "### üèÅ Start Celebrity Recognition Job (Video)  \n",
        "Here we submit a video file for celebrity recognition via Rekognition‚Äôs asynchronous job API and retrieves the job ID using `start_celebrity_recognition`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km4GTRGb31uc"
      },
      "outputs": [],
      "source": [
        "#add video word to the name\n",
        "rekognitionVideoCelebJob = rekognition.start_celebrity_recognition(\n",
        "    Video={\n",
        "        \"S3Object\": {\n",
        "            \"Bucket\": bucket,\n",
        "            \"Name\": videoFileName,\n",
        "        }\n",
        "    },\n",
        ")\n",
        "\n",
        "rekognitionVideoCelebJobID = rekognitionVideoCelebJob[\"JobId\"]\n",
        "print(\"AWS Rekognition Job Id: {0}\".format(rekognitionVideoCelebJobID))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMtzg-Fh31ud"
      },
      "source": [
        "#### ‚è±Ô∏è Poll Rekognition Job Status (Celebrities)  \n",
        "We continuously poll the celebrity recognition job until the job is marked as `SUCCEEDED`. This is essential for async processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-fjLHec31ud"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "getRecognitionCelebJob = rekognition.get_celebrity_recognition(JobId=rekognitionVideoCelebJobID, SortBy=\"TIMESTAMP\")\n",
        "\n",
        "while getRecognitionCelebJob[\"JobStatus\"] == \"IN_PROGRESS\":\n",
        "    time.sleep(5)\n",
        "    print(\"*\", end=\"\")\n",
        "    getRecognitionCelebJob = rekognition.get_celebrity_recognition(JobId=rekognitionVideoCelebJobID, SortBy=\"TIMESTAMP\")\n",
        "\n",
        "print(\"Detecting Celebrities in Video: \"+ getRecognitionCelebJob[\"JobStatus\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pObRbbpR31ud"
      },
      "source": [
        "### üì§ Let's Display and Examine Celebrity Detection Results  \n",
        "Here we display the raw JSON results returned after celebrity detection from the video file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIO8Adzu31ue"
      },
      "outputs": [],
      "source": [
        "display(getRecognitionCelebJob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRh6O-tz31ue"
      },
      "source": [
        "#### üìã Extract and Summarize Celebrity Appearances  \n",
        "We parse the detection results and format them in a readable structure showing the celebrity name and time range they appeared in.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rsXPOp231ue"
      },
      "outputs": [],
      "source": [
        "celebs = {}\n",
        "listHeader = \"List of Celebrities Detected: \\n\"\n",
        "videoDetails =\"\"\n",
        "celebsString = \"\"\n",
        "\n",
        "# All detected celebrities per frame\n",
        "for celebrity in getRecognitionCelebJob[\"Celebrities\"]:\n",
        "    if \"Celebrity\" in celebrity:\n",
        "        confidence = celebrity[\"Celebrity\"][\"Confidence\"]\n",
        "        if confidence > 95: #Confidence threshold\n",
        "            timeStamp = celebrity[\"Timestamp\"]\n",
        "            celebName = celebrity[\"Celebrity\"][\"Name\"]\n",
        "            videoDetails = videoDetails + \"Celebrity found at time {} ms: {} (Confidence: {})\\n\".format(timeStamp, celebName, round(confidence, 2))\n",
        "            if not celebName in celebs:\n",
        "                celebs[celebName] = celebName\n",
        "\n",
        "\n",
        "# Keep only unique faces found in the clip\n",
        "for celeb in celebs:\n",
        "    celebsString = celebsString + \"Name: {}\\n\".format(celeb)\n",
        "\n",
        "# Print the results\n",
        "print(listHeader)\n",
        "print(celebsString)\n",
        "print (\"List Details:\")\n",
        "print(videoDetails)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qkf3ODkq31ue"
      },
      "source": [
        "### üßç Let's Display a Local User Image\n",
        "This image will be used to test the celebrity recognition API on a locally available image of me.\n",
        "Then we run Rekognition on my image to detect if any known celebrities are identified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3zhFvGx31uf"
      },
      "outputs": [],
      "source": [
        "meCelebrityPicture = \"media/myPicture.png\" #myPicture\n",
        "display(IImage(url=s3.generate_presigned_url(\"get_object\", Params={\"Bucket\": bucket, \"Key\": meCelebrityPicture}),width=350, height=150))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCCVxRTf31uf"
      },
      "outputs": [],
      "source": [
        "# Call Amazon Rekognition to recognize my picture\n",
        "recognizedCelebsResponse = rekognition.recognize_celebrities(\n",
        "    Image={\n",
        "        \"S3Object\": {\n",
        "            \"Bucket\": bucket,\n",
        "            \"Name\": meCelebrityPicture,\n",
        "        }\n",
        "    }\n",
        ")\n",
        "display(recognizedCelebsResponse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR6bok3T31ug"
      },
      "source": [
        "#### üö´ Draw Bounding Boxes on Unrecognized Faces  \n",
        "Highlight faces found in the image that weren‚Äôt matched with any known celebrity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHEenmyl31uh"
      },
      "outputs": [],
      "source": [
        "facesBoundingBoxes = [] #\n",
        "facesList = recognizedCelebsResponse[\"UnrecognizedFaces\"]\n",
        "if facesList:\n",
        "    for face in facesList:\n",
        "        facesBoundingBoxes.append((\"Unrecognized Persons\", face[\"BoundingBox\"]))\n",
        "        drwBoundingBoxes(meCelebrityPicture, facesBoundingBoxes)\n",
        "else:\n",
        "    display(IImage(url=s3.generate_presigned_url(\"get_object\", Params={\"Bucket\": bucket, \"Key\": meCelebrityPicture}),width=350, height=150))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjHK7TgN31uh"
      },
      "source": [
        "### üö®üö®üö® End of Part 1 üö®üö®üö®\n",
        "### üö®üö®üö® WARNING: Don't Forget to Release Resources üö®üö®üö®\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3W49xBRXnsE"
      },
      "source": [
        "#  Part 2: Content Moderation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtF018rqX4NG"
      },
      "source": [
        "### üñºÔ∏è Display Image for Content Moderation  \n",
        "We display another image from the S3 bucket, this time for content moderation tasks (i.e., detecting unsafe or explicit content).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEsOlGdPX0hT"
      },
      "outputs": [],
      "source": [
        "imageFileName = \"media/mi6arms.jpg\"\n",
        "display(IImage(url=s3.generate_presigned_url(\"get_object\", Params={\"Bucket\": bucket, \"Key\": imageFileName}), width=700, height=500))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GDSRrXgX-Fg"
      },
      "source": [
        "### üö® Detect Moderation Labels (Image)  \n",
        "Call Rekognition's moderation API `detect_moderation_labels` to identify unsafe content (nudity, violence, etc.) in the selected image.\n",
        "\n",
        "#### To Print Moderation Results:  \n",
        "We iterate through moderation labels to display detected content categories and their confidence scores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub-Jg0IsYAUW"
      },
      "outputs": [],
      "source": [
        "detectedLabelsResponse = rekognition.detect_moderation_labels(\n",
        "    Image={\n",
        "        \"S3Object\": {\n",
        "            \"Bucket\": bucket,\n",
        "            \"Name\": imageFileName,\n",
        "        }\n",
        "    }\n",
        ")\n",
        "display(detectedLabelsResponse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqhjjvbTYVrv"
      },
      "outputs": [],
      "source": [
        "\n",
        "for detectedLabel in detectedLabelsResponse[\"ModerationLabels\"]:\n",
        "    print(\"- Label Detected: {} (Confidence: {})\".format(detectedLabel[\"Name\"], detectedLabel[\"Confidence\"]))\n",
        "    print(\"  - Parent Label: {}\".format(detectedLabel[\"ParentName\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cfRGK7PYX7J"
      },
      "source": [
        "# Let's use Amazon Rekognition for Content Moderation in Video üìπ\n",
        "\n",
        "#### First We Display Video üé• Contents for Moderation\n",
        "Display a trailer or video clip from S3 that will be used for content moderation analysis in the following steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoImhxo4Ylbm"
      },
      "outputs": [],
      "source": [
        "videoFileName = \"media/mi6Trailer.mp4\"\n",
        "\n",
        "videoS3URL = s3.generate_presigned_url(\"get_object\", Params={\"Bucket\": bucket, \"Key\": videoFileName})\n",
        "videoHTML = \"<video controls='controls' autoplay width='640' height='360' name='Video' src='{0}'></video>\".format(videoS3URL)\n",
        "display(HTML(videoHTML))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhoaC5jfYoFT"
      },
      "source": [
        "#### Start Moderation Job (Video)  \n",
        "Send the selected video for moderation via Rekognition's video API `start_content_moderation` and retrieve the job ID for later polling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EF_M-DyYrIp"
      },
      "outputs": [],
      "source": [
        "# Start content moderation job\n",
        "modVideoLabelDetectionJob = rekognition.start_content_moderation(\n",
        "    Video={\n",
        "        \"S3Object\": {\n",
        "            \"Bucket\": bucket,\n",
        "            \"Name\": videoFileName,\n",
        "        }\n",
        "    },\n",
        "    MinConfidence=50.0\n",
        ")\n",
        "\n",
        "modVideoJobId = modVideoLabelDetectionJob[\"JobId\"]\n",
        "print(\"AWS Rekognition Job Id: {0}\".format(modVideoJobId))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m15ZaLWmYyDs"
      },
      "source": [
        "### ‚è±Ô∏è Poll Moderation Job Status  \n",
        "Wait and check periodically until the video moderation job is completed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4NIUnofYulm"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "getModLabelId = rekognition.get_content_moderation(JobId=modVideoJobId, SortBy=\"TIMESTAMP\")\n",
        "\n",
        "while getModLabelId[\"JobStatus\"] == \"IN_PROGRESS\":\n",
        "    time.sleep(5)\n",
        "    print(\"*\", end=\"\")\n",
        "    getModLabelId = rekognition.get_content_moderation(JobId=modVideoJobId, SortBy=\"TIMESTAMP\")\n",
        "print(\"Detecting Moderation Labels in Video: \"+ getModLabelId[\"JobStatus\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh4yiJc-Y2rI"
      },
      "source": [
        "### üì§ Display Moderation Results  \n",
        "Print out the full moderation results from the video for inspection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjQ1BnPfY5gD"
      },
      "outputs": [],
      "source": [
        "display(getModLabelId)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDe557SYZFEK"
      },
      "source": [
        "### üìë Summarize Unsafe Labels from Video  \n",
        "Extract moderation labels (e.g., nudity, drugs, violence) with timestamps to understand where unsafe content appears in the video.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbFhHCsBZHMA"
      },
      "outputs": [],
      "source": [
        "labelsObjectDict = {}\n",
        "videoDetails =\"\"\n",
        "labelsString = \"\"\n",
        "\n",
        "for modLabel in getModLabelId[\"ModerationLabels\"]:\n",
        "    timeStamp = modLabel[\"Timestamp\"]\n",
        "    confidence = modLabel[\"ModerationLabel\"][\"Confidence\"]\n",
        "    labelName = modLabel[\"ModerationLabel\"][\"Name\"]\n",
        "    videoDetails = videoDetails + \"Moderation Label Detected at time {} ms: {} (Confidence: {})\\n\".format(timeStamp, labelName, round(confidence, 2))\n",
        "    if labelName in labelsObjectDict:\n",
        "        labelFound = labelsObjectDict[labelName]\n",
        "        labelsObjectDict[labelName] = {\"Name\": labelName, \"Count\": 1 + labelFound[\"Count\"]}\n",
        "    else:\n",
        "        labelsObjectDict[labelName] = {\"Name\": labelName, \"Count\": 1}\n",
        "\n",
        "# Similar to unique faces in detecting celebrities, we need unique moderation objects\n",
        "for label in labelsObjectDict:\n",
        "    labelsString = labelsString + \"Name: {}, Count: {}\\n\".format(label, labelsObjectDict[label][\"Count\"])\n",
        "\n",
        "print(\"List of Moderation Labels Detected:\\n\")\n",
        "print(videoDetails)\n",
        "print(\"Count of Labels Detected:\\n\")\n",
        "print(labelsString)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_xggLJ7XxO_"
      },
      "source": [
        "### üö®üö®üö®  End of Part 2 üö®üö®üö®\n",
        "### üö®üö®üö® WARNING: Don't Forget to Release Resources üö®üö®üö®\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLjRQ4rDZbX4"
      },
      "source": [
        "# Part 3 :  Text detection\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ST2u-zO22JS"
      },
      "source": [
        "### üñºÔ∏è Display Poster Image for Text Detection  \n",
        "Display an image containing textual content, such as posters or flyers, to be used in text detection tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3jrf7M53Xa5"
      },
      "outputs": [],
      "source": [
        "imageFileName = \"media/mi6poster.jpg\"\n",
        "display(IImage(url=s3.generate_presigned_url(\"get_object\", Params={\"Bucket\": bucket, \"Key\": imageFileName}), width=350, height=250))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du4UlY6ekwcN"
      },
      "source": [
        "### üîç Detect Text in Image  \n",
        "Use Rekognition API `detect_text` to detect printed or handwritten text in the image. The JSON response includes word positions and types.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJEhg-Es41qe"
      },
      "outputs": [],
      "source": [
        "detectedTxtResponse = rekognition.detect_text(\n",
        "    Image={\n",
        "        \"S3Object\": {\n",
        "            \"Bucket\": bucket,\n",
        "            \"Name\": imageFileName,\n",
        "        }\n",
        "    },\n",
        "    Filters={\"WordFilter\": {\"MinConfidence\": 90}},\n",
        ")\n",
        "\n",
        "display(detectedTxtResponse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFyqB5XZ4Qvb"
      },
      "source": [
        "### üì¶ Draw Bounding Boxes on Detected Text  \n",
        "Use bounding boxes to visualize the detected words or lines directly on the image using the helper function `drwBoundingBoxes`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ypsl_9Q4NJA"
      },
      "outputs": [],
      "source": [
        "textBoxes = []\n",
        "txtsDetected = detectedTxtResponse[\"TextDetections\"]\n",
        "for txtDetected in txtsDetected:\n",
        "    textBoxes.append((txtDetected[\"Type\"], txtDetected[\"Geometry\"][\"BoundingBox\"]))\n",
        "drwBoundingBoxes(imageFileName, textBoxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abOdSkd4lLCQ"
      },
      "source": [
        "### üìù Highlight Specific Keywords  \n",
        "We search the detected text for specific keywords (e.g., \"Tom Cruise\") and print matching segments for content filtering or search applications.\n",
        "Your Turn: Write code to darw bounding boxes only on wanted words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU5s9qD23yEr"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "targetWordsList = [\"tom\", \"tom cruise\", \"fallout\"]\n",
        "\n",
        "for txtDetected in detectedTxtResponse[\"TextDetections\"]:\n",
        "    txt = txtDetected[\"DetectedText\"].translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    if (txtDetected[\"Type\"] == \"WORD\" or txtDetected[\"Type\"] == \"LINE\")  and txt.lower() in targetWordsList:\n",
        "        print(\"Target word found: {}\".format(txtDetected[\"DetectedText\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37WkP_rc4bjo"
      },
      "source": [
        "### üìÑ Re-run Text Detection with Filters\n",
        "Re-execute the Rekognition text detection API to verify and re-extract information from the image in certain rgions or with certain confidence ....\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Brz9qML4int"
      },
      "outputs": [],
      "source": [
        "imageFileName = \"media/mi6poster.jpg\"\n",
        "\n",
        "detectedTxtResponse = rekognition.detect_text(\n",
        "    Image={\n",
        "        \"S3Object\": {\n",
        "            \"Bucket\": bucket,\n",
        "            \"Name\": imageFileName,\n",
        "        }\n",
        "    },\n",
        "    Filters={\n",
        "        \"WordFilter\": {\"MinConfidence\": 90, \"MinBoundingBoxHeight\": 0.05, \"MinBoundingBoxWidth\": 0.02},\n",
        "        #\"RegionsOfInterest\": [\n",
        "        #    {\"BoundingBox\": {\"Width\": 0.1, \"Height\": 0.05, \"Left\": 0.01, \"Top\": 0.01}},\n",
        "        #],\n",
        "    },\n",
        ")\n",
        "\n",
        "display(detectedTxtResponse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhtfga-JlvDY"
      },
      "source": [
        "### üñ®Ô∏è Print Detected Words and Lines  \n",
        "List out each detected word and line with their types (WORD or LINE), useful for textual analysis or indexing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hzptt9Kr41qk"
      },
      "outputs": [],
      "source": [
        "\n",
        "for textDetection in detectedTxtResponse[\"TextDetections\"]:\n",
        "    text = textDetection[\"DetectedText\"]\n",
        "    if textDetection[\"Type\"] == \"WORD\":\n",
        "        print(\"Word: {}\".format(textDetection[\"DetectedText\"]))\n",
        "    if textDetection[\"Type\"] == \"LINE\":\n",
        "        print(\"Line: {}\".format(textDetection[\"DetectedText\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYcdU0vf4wnn"
      },
      "source": [
        "## üé¨ Can we do the same with Videos: Star Wars Introduction\n",
        "We generate and display a presigned URL for a video to be used for text detection within video content.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZBIYP-C5Hnd"
      },
      "outputs": [],
      "source": [
        "videoFileName = \"media/starWarsIntro.mp4\"\n",
        "\n",
        "videoS3URL = s3.generate_presigned_url(\"get_object\", Params={\"Bucket\": bucket, \"Key\": videoFileName})\n",
        "\n",
        "videoHTML = \"<video controls='controls' autoplay width='640' height='360' name='Video' src='{0}'></video>\".format(videoS3URL)\n",
        "\n",
        "display(HTML(videoHTML))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg-yhsyO5O1K"
      },
      "source": [
        "### üèÅ Start Text Detection Job (Video)  \n",
        "Submit a video to Rekognition‚Äôs text detection API `start_text_detection` and start the async job for extracting text from frames and then get the job id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIcX31QO5N6W"
      },
      "outputs": [],
      "source": [
        "startVideoTxtDetectionJob = rekognition.start_text_detection(\n",
        "    Video={\n",
        "        \"S3Object\": {\n",
        "            \"Bucket\": bucket,\n",
        "            \"Name\": videoFileName,\n",
        "        }\n",
        "    },\n",
        ")\n",
        "videoTextDetectionJobId = startVideoTxtDetectionJob[\"JobId\"]\n",
        "print(\"Amazon Rekognition Job Id: {0}\".format(videoTextDetectionJobId))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jMtO_le5STX"
      },
      "source": [
        "### ‚è±Ô∏è Poll Text Detection Job  \n",
        "Keep checking the job status until Rekognition returns the full text detection results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9r27SyY5TDL"
      },
      "outputs": [],
      "source": [
        "\n",
        "getVideoTxtDetectionJob = rekognition.get_text_detection(JobId=videoTextDetectionJobId)\n",
        "\n",
        "while getVideoTxtDetectionJob[\"JobStatus\"] == \"IN_PROGRESS\":\n",
        "    time.sleep(5)\n",
        "    print(\"*\", end=\"\")\n",
        "\n",
        "    getVideoTxtDetectionJob = rekognition.get_text_detection(JobId=videoTextDetectionJobId)\n",
        "\n",
        "print(\"Amazon Rekognition Job Status: \"+getVideoTxtDetectionJob[\"JobStatus\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8P14OfS5f2w"
      },
      "source": [
        "### üì§ Display Text Detection Results  \n",
        "Print the raw output of detected text segments from the processed video.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7LAr9GB5h1B"
      },
      "outputs": [],
      "source": [
        "display(getVideoTxtDetectionJob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHxOxUoB5kSQ"
      },
      "source": [
        "### üö© Filter Words in Video  \n",
        "We can now search for specific terms or keywords from the detected text in the video and highlight those of interest.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvDxOW6H5mmR"
      },
      "outputs": [],
      "source": [
        "targetText = [\"POWER\", \"DESTROY\", \"SPIES\", \"PLANS\", \"EVIL\", \"REBEL\"] #add Lord Vader\n",
        "txtDict = {}\n",
        "detectedTextInVideo= \"\"\n",
        "detectedTextStats =\"\"\n",
        "\n",
        "\n",
        "for textDetection in getVideoTxtDetectionJob[\"TextDetections\"]:\n",
        "    if textDetection[\"TextDetection\"][\"Type\"] == \"WORD\":\n",
        "        timeStamp = textDetection[\"Timestamp\"]\n",
        "        confidence = textDetection[\"TextDetection\"][\"Confidence\"]\n",
        "        detectedText = textDetection[\"TextDetection\"][\"DetectedText\"]\n",
        "\n",
        "        if detectedText in targetText:\n",
        "            print(\"Found target text at time: {} ms: Category{} (Confidence: {})\".format(timeStamp, detectedText, round(confidence, 2)))\n",
        "            detectedTextInVideo = detectedTextInVideo + \"Target Text Found at time {} ms: {} (Confidence: {})\\n\".format(timeStamp, detectedText, round(confidence, 2))\n",
        "        if detectedText in txtDict:#You can add a condition to count only traget text ONLY\n",
        "            txtFound = txtDict[detectedText]\n",
        "            txtDict[detectedText] = {\"Text\": detectedText, \"Count\": 1 + txtFound[\"Count\"]}\n",
        "        else:\n",
        "            txtDict[detectedText] = {\"Text\": detectedText, \"Count\": 1}\n",
        "\n",
        "for txt in txtDict:\n",
        "    detectedTextStats = detectedTextStats + \"Name: {}, Count: {}\\n\".format(txt, txtDict[txt][\"Count\"])\n",
        "\n",
        "print(\"List of detected target text: \\n\")\n",
        "print(detectedTextInVideo)\n",
        "print(\"\\n\\nDetected Text Statistics:\\n\")\n",
        "print(detectedTextStats)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL3hyM3XXnY3"
      },
      "source": [
        "# üö®üö®üö® End of Part 3 üö®üö®üö®\n",
        "Remember to Shutdown all instances and release all resources\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydjik2sBWRpG"
      },
      "source": [
        "\n",
        "# Read more from Amazon\n",
        "- https://docs.aws.amazon.com/rekognition/latest/dg/celebrities.html\n",
        "- https://docs.aws.amazon.com/rekognition/latest/dg/API_RecognizeCelebrities.html\n",
        "- https://docs.aws.amazon.com/rekognition/latest/dg/API_StartCelebrityRecognition.html\n",
        "- https://docs.aws.amazon.com/rekognition/latest/dg/API_GetCelebrityRecognition.html\n",
        "- https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectText.html\n",
        "- https://docs.aws.amazon.com/rekognition/latest/dg/API_StartTextDetection.html\n",
        "- https://docs.aws.amazon.com/rekognition/latest/dg/API_GetTextDetection.html\n",
        "- https://docs.aws.amazon.com/rekognition/latest/dg/text-detecting-video-procedure.html.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua7iRGenWSI6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzXlqofvXGhi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}